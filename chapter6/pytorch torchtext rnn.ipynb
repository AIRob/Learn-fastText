{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration for this notebook is from https://www.kaggle.com/abefetterman/pytorch-gru-pooling-with-torchtext/code\n",
    "\n",
    "https://gist.github.com/ceshine/50a71e266722d0b7b00e2641fc86eb6f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import logging\n",
    "\n",
    "NLP = spacy.load('en')\n",
    "MAX_CHARS = 20000\n",
    "VAL_RATIO = 0.2\n",
    "LOGGER = logging.getLogger(\"yelp\")\n",
    "\n",
    "id_label = 'id'\n",
    "text_label = 'text'\n",
    "stars_label = 'stars'\n",
    "\n",
    "yelp_reviews = 'yelp_review.csv'\n",
    "\n",
    "# embedding_file = 'crawl-300d-2M.vec'\n",
    "\n",
    "# some iterators produce StopIteration, which is no longer a warning, we don't need to hear about it\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 328.74 MiB, increment: 0.33 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit\n",
    "from torchtext.vocab import FastText\n",
    "vectors = FastText('simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 466.30 MiB, increment: 0.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning.\n",
    "    Original from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %memit\n",
    "# df = pd.read_csv('yelp_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['text', 'stars']]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_csv(df, seed=999):\n",
    "    df['text'] = df['text'].apply(clean_str)\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "    df_train.to_csv(\"yelp_tmp/dataset_train.csv\", index=False)\n",
    "    df_test.to_csv(\"yelp_tmp/dataset_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# prepare_csv(df)\n",
    "# df = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 466.54 MiB, increment: 0.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit\n",
    "# Define all the types of fields\n",
    "# pip install spacy for the tokenizer to work (or remove to use default)\n",
    "TEXT = data.Field(lower=True, include_lengths=True, fix_length=150, tokenize='spacy')\n",
    "LABEL = data.Field(sequential=True, use_vocab=False)\n",
    "\n",
    "# we use the index field to re-sort test data after processing\n",
    "INDEX = data.Field(sequential=False)\n",
    "\n",
    "train_fields=[\n",
    "#     (id_label, INDEX),\n",
    "    (text_label, TEXT),\n",
    "    (stars_label, LABEL)\n",
    "]\n",
    "\n",
    "train_fields=[\n",
    "#     (id_label, INDEX),\n",
    "    (text_label, TEXT),\n",
    "    (stars_label, LABEL)\n",
    "]\n",
    "\n",
    "train = data.TabularDataset(\n",
    "    path='yelp_tmp/dataset_train.csv', format='csv', skip_header=True,\n",
    "    fields=train_fields)\n",
    "\n",
    "test_fields=[\n",
    "    (id_label, INDEX),\n",
    "    (text_label, TEXT),\n",
    "    (stars_label, LABEL)\n",
    "]\n",
    "test = data.TabularDataset(\n",
    "        path='yelp_tmp/dataset_val.csv', format='csv', skip_header=True,\n",
    "        fields=test_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 30000\n",
    "TEXT.build_vocab(train, test, vectors=vectors, max_size=max_size)\n",
    "\n",
    "INDEX.build_vocab(test)\n",
    "\n",
    "# print vocab information\n",
    "ntokens = len(TEXT.vocab)\n",
    "print('ntokens', ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.BucketIterator(train, batch_size=32,\n",
    "                            sort_key=lambda x: len(x.text),\n",
    "                            sort_within_batch=True, repeat=False)\n",
    "test = data.BucketIterator(test, batch_size=128,\n",
    "                           sort_key=lambda x: len(x.text),\n",
    "                           sort_within_batch=True, train=False, repeat=False)\n",
    "\n",
    "def get_text(batch):\n",
    "    return getattr(batch, text_label)\n",
    "def get_labels(batch):\n",
    "    # Get the labels as one tensor from the batch object\n",
    "    return torch.cat([getattr(batch, label).unsqueeze(1) for label in label_cols], dim=1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, ntoken, ninp, nhid, nout, nlayers, dropemb=0.2, droprnn=0.0, bidirectional=True):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.drop = nn.Dropout2d(dropemb)\n",
    "        self.ndir = 2 if bidirectional else 1\n",
    "        assert rnn_type in ['LSTM', 'GRU'], 'RNN type is not supported'\n",
    "        if rnn_type == 'LSTM':\n",
    "            self.rnns = [torch.nn.LSTM(ninp if l == 0 else nhid*self.ndir, nhid, 1, dropout=droprnn, bidirectional=bidirectional) for l in range(nlayers)]\n",
    "        if rnn_type == 'GRU':\n",
    "            self.rnns = [torch.nn.GRU(ninp if l == 0 else nhid*self.ndir, nhid, 1, dropout=droprnn, bidirectional=bidirectional) for l in range(nlayers)]\n",
    "        \n",
    "        self.rnns = torch.nn.ModuleList(self.rnns)\n",
    "        self.avg_pool = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = torch.nn.AdaptiveMaxPool1d(1)\n",
    "        self.decoder = nn.Linear(nhid*self.ndir*2, nout)\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def forward(self, input, lengths=None):\n",
    "        emb = self.encoder(input)\n",
    "        \n",
    "        raw_output = self.drop(emb)\n",
    "        \n",
    "        if lengths is not None:\n",
    "            lengths = lengths.view(-1).tolist()\n",
    "            raw_output = nn.utils.rnn.pack_padded_sequence(raw_output, lengths)\n",
    "            \n",
    "        for rnn in self.rnns:\n",
    "            raw_output,_ = rnn(raw_output)\n",
    "        \n",
    "        if lengths is not None:\n",
    "            raw_output, lengths = nn.utils.rnn.pad_packed_sequence(raw_output)\n",
    "            \n",
    "        bsz = raw_output.size(1)\n",
    "        rnn_avg = self.avg_pool(raw_output.permute(1,2,0))\n",
    "        rnn_max = self.max_pool(raw_output.permute(1,2,0))\n",
    "        rnn_out = torch.cat([rnn_avg.view(bsz,-1),rnn_max.view(bsz,-1)], dim=1)\n",
    "            \n",
    "        result = self.decoder(rnn_out)\n",
    "        return self.decoder(rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "nhidden=100\n",
    "emsize=300\n",
    "nlayers = 1\n",
    "dropemb = 0.2\n",
    "droprnn = 0.0\n",
    "model = RNNModel('GRU', ntokens, emsize, nhidden, 6, nlayers, dropemb=dropemb, droprnn=droprnn, bidirectional=True)\n",
    "model.encoder.weight.data.copy_(TEXT.vocab.vectors)\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.7, 0.99))\n",
    "if use_cuda:\n",
    "    model=model.cuda()\n",
    "    criterion=criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_count = 0\n",
    "    model.train() \n",
    "    t = tqdm(train)\n",
    "    for batch in t:\n",
    "        (x,xl) = get_text(batch)\n",
    "        y = get_labels(batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(x, lengths=xl)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]*len(x)\n",
    "        running_count += len(x)\n",
    "        t.set_postfix(loss=(running_loss/running_count))\n",
    "\n",
    "    epoch_loss = running_loss / running_count\n",
    "\n",
    "    print('Epoch: {}, Loss: {:.5f}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(batch):\n",
    "    return getattr(batch, id_label).data.cpu().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_preds = np.zeros((len(INDEX.vocab), 6))\n",
    "model.eval()\n",
    "for batch in test:\n",
    "    (x,xl) = get_text(batch)\n",
    "    ids = get_ids(batch)\n",
    "    preds=model(x,lengths=xl)\n",
    "    preds = preds.data.cpu().numpy()\n",
    "    preds = 1/(1+np.exp(-np.clip(preds,-10,10)))\n",
    "    test_preds[ids]=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
